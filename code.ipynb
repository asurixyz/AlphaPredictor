{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84743,"databundleVersionId":9548952,"sourceType":"competition"},{"sourceId":9414782,"sourceType":"datasetVersion","datasetId":5717624}],"dockerImageVersionId":30761,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"#Importing the libraries needed\nimport numpy as np\nimport pandas as pd\nfrom scipy.stats import kurtosis, skew\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import GridSearchCV\n\n# Load training and test data\ntrain_data = pd.read_csv('/kaggle/input/taramani-quant-research-contest-tqrc/train_data.csv')\ntest_data = pd.read_csv('/kaggle/input/taramani-quant-research-contest-tqrc/final_test_data.csv')","metadata":{"execution":{"iopub.status.busy":"2024-09-16T18:22:11.760952Z","iopub.execute_input":"2024-09-16T18:22:11.761892Z","iopub.status.idle":"2024-09-16T18:22:12.824483Z","shell.execute_reply.started":"2024-09-16T18:22:11.761836Z","shell.execute_reply":"2024-09-16T18:22:12.823574Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Features for Limit Order Book Alpha Prediction\n\nWe list the features that we have to predict the alpha from the Limit Order Book (LOB).\n\n## 1. Price Features\n- **Mid-price**:  \n  $$ \\text{midprice}_i = \\frac{\\text{bid_price}_i + \\text{ask_price}_i}{2} $$\n  \n- **Weighted mid-price**:  \n  $$ \\text{weighted_mid_price} = \\frac{\\text{bid_price}_1 \\cdot \\text{ask_volume}_1 + \\text{ask_price}_1 \\cdot \\text{bid_volume}_1}{\\text{bid_volume}_1 + \\text{ask_volume}_1} $$\n\n## 2. Spread Features\n- **Bid-ask spread**:  \n  $$ \\text{spread}_i = \\text{ask_price}_i - \\text{bid_price}_i $$\n\n- **Spread skew**:  \n  $$ \\text{spread_skew} = \\frac{\\text{spread}_1}{\\text{spread}_5} $$\n\n## 3. Volume Imbalance Features\n- **Volume imbalance**:  \n  $$ \\text{volume_imbalance}_i = \\frac{\\text{bid_volume}_i - \\text{ask_volume}_i}{\\text{bid_volume}_i + \\text{ask_volume}_i} $$\n\n- **Bid-ask imbalance**:  \n  Ratio of total bid volume to total ask volume across all levels.\n\n## 4. Order Flow Features\n- **Order flow imbalance**:  \n  Measures the imbalance in price changes between bid and ask sides.\n\n## 5. Market Depth Features\n- **Total depth**:  \n  Sum of volumes across all levels on both sides.\n  \n- **Market depth ratio**:  \n  Ratio of total bid volume to total ask volume.\n\n## 6. Price Movement and Momentum Features\n- **Price momentum**:  \n  $$ \\text{price_momentum} = \\frac{\\text{last_trade_price} - \\text{midprice}_1}{\\text{midprice}_1} $$\n\n- **Mid-price slope**:  \n  Rate of change of mid-price across levels.\n\n## 7. Liquidity Features\n- **Liquidity impact**:  \n  Ratio of recent order counts to total order count.\n\n- **Liquidity weight**:  \n  Ratio of level 1 volume to level 2 volume.\n\n## 8. Market Pressure Features\n- **Market pressure**:  \n  $$ \\text{market_pressure} = \\frac{\\text{recent_buy_orders} - \\text{recent_sell_orders}}{\\text{total_orders}} $$\n\n- **Order book pressure**:  \n  Ratio of total bid volume to total ask volume.\n\n## 9. Price Sensitivity Features\n- **Bid/Ask price sensitivity**:  \n  Rate of price change relative to volume change.\n\n## 10. VWAP Features\n- **Volume Weighted Average Price (VWAP)**:  \n  $$ \\text{VWAP}_i = \\frac{\\text{bid_price}_i \\cdot \\text{bid_volume}_i + \\text{ask_price}_i \\cdot \\text{ask_volume}_i}{\\text{bid_volume}_i + \\text{ask_volume}_i} $$\n\n## 11. Relative Volume Features\n- **Relative volume at best bid/ask**:  \n  Ratio of volume at best bid/ask to total volume on that side.\n\n## 12. Statistical Features\n- **Mean and cumulative sum of prices and volumes across levels.**\n- **Volume momentum**:  \n  Rate of change of volume across levels.\n\n## 13. Market Skew and Depth Imbalance Features\n- **Market skew**:  \n  Measure of asymmetry in volume distribution.\n\n- **Depth imbalance**:  \n  Various ratios comparing bid and ask volumes at different levels.\n\nThese features capture different aspects of the limit order book dynamics, including price trends, volume imbalances, liquidity, and market pressure.\n","metadata":{}},{"cell_type":"code","source":"# Feature Engineering\ndef create_features(df):\n    # Mid-Price\n    for i in range(1, 6):\n        df[f'midprice_{i}'] = (df[f'bid_price_{i}'] + df[f'ask_price_{i}']) / 2\n    \n    df['weighted_mid_price_1'] = (df['bid_price_1'] * df['ask_volume_1'] + df['ask_price_1'] * df['bid_volume_1']) / (df['bid_volume_1'] + df['ask_volume_1'])\n\n    # Price Spread, Weighted Spread, Normalized Spread, and Volume Imbalance\n    for i in range(1, 6):\n        df[f'spread_{i}'] = df[f'ask_price_{i}'] - df[f'bid_price_{i}']\n        df[f'weighted_spread_{i}'] = df[f'ask_volume_{i}'] * df[f'ask_price_{i}'] - df[f'bid_price_{i}'] * df[f'bid_volume_{i}']\n        df[f'norm_spread_{i}'] = df[f'spread_{i}'] / df[f'midprice_{i}']\n        df[f'volume_imbalance_{i}'] = (df[f'bid_volume_{i}'] - df[f'ask_volume_{i}']) / (df[f'bid_volume_{i}'] + df[f'ask_volume_{i}'])\n\n\n    df['bid_ask_imbalance'] = df[[f'bid_volume_{i}' for i in range(1, 6)]].sum(axis=1) / (df[[f'ask_volume_{i}' for i in range(1, 6)]].sum(axis=1) + df[[f'bid_volume_{i}' for i in range(1, 6)]].sum(axis=1))\n\n    # Order Flow (difference in price levels over time)\n    df['order_flow'] = (df['bid_price_1'] - df['ask_price_1']) + (df['bid_volume_1'] - df['ask_volume_1'])\n\n    # Depth (Total Volume at Top 5 Levels)\n    df['depth'] = (df[['bid_volume_1', 'bid_volume_2', 'bid_volume_3', 'bid_volume_4', 'bid_volume_5']].sum(axis=1) +\n                   df[['ask_volume_1', 'ask_volume_2', 'ask_volume_3', 'ask_volume_4', 'ask_volume_5']].sum(axis=1))\n\n\n   # Basic price features\n    df['midprice_1'] = (df['bid_price_1'] + df['ask_price_1']) / 2\n    df['midprice_5'] = (df['bid_price_5'] + df['ask_price_5']) / 2\n    df['weighted_mid_price_1'] = (df['bid_price_1'] * df['ask_volume_1'] + df['ask_price_1'] * df['bid_volume_1']) / (df['bid_volume_1'] + df['ask_volume_1'])\n\n    # Spread features\n    df['spread_1'] = df['ask_price_1'] - df['bid_price_1']\n    df['spread_5'] = df['ask_price_5'] - df['bid_price_5']\n    df['spread_skew'] = df['spread_1'] / df['spread_5']\n    df['spread_depth_ratio_1'] = df['spread_1'] / (df['bid_volume_1'] + df['ask_volume_1'] + 1e-9)\n\n    # Volume imbalance features\n    for i in range(1, 6):\n        df[f'volume_imbalance_{i}'] = (df[f'bid_volume_{i}'] - df[f'ask_volume_{i}']) / (df[f'bid_volume_{i}'] + df[f'ask_volume_{i}'] + 1e-9)\n    df['bid_ask_imbalance'] = df[[f'bid_volume_{i}' for i in range(1, 6)]].sum(axis=1) / (df[[f'ask_volume_{i}' for i in range(1, 6)]].sum(axis=1) + df[[f'bid_volume_{i}' for i in range(1, 6)]].sum(axis=1))\n\n    # Order flow features\n    df['order_flow'] = (df['bid_price_1'] - df['ask_price_1']) + (df['bid_volume_1'] - df['ask_volume_1'])\n    df['order_flow_imbalance'] = ((df['bid_price_1'] - df['bid_price_2']) - (df['ask_price_1'] - df['ask_price_2'])) / ((df['bid_price_1'] + df['ask_price_1']) / 2)\n\n    # Market depth features\n    df['depth'] = df[[f'bid_volume_{i}' for i in range(1, 6)]].sum(axis=1) + df[[f'ask_volume_{i}' for i in range(1, 6)]].sum(axis=1)\n    df['market_depth_ratio'] = df[[f'bid_volume_{i}' for i in range(1, 6)]].sum(axis=1) / df[[f'ask_volume_{i}' for i in range(1, 6)]].sum(axis=1)\n\n    # Price movement and momentum features\n    df['price_momentum'] = (df['last_trade_price'] - df['midprice_1']) / df['midprice_1']\n    df['midprice_slope'] = (df['midprice_5'] - df['midprice_1']) / 5\n    df['bid_ask_slope'] = (df['ask_price_5'] - df['ask_price_1']) / (df['bid_price_1'] - df['bid_price_5'])\n\n    # Liquidity features\n    df['liquidity_impact'] = (df['recent_buy_order_count'] + df['recent_sell_order_count']) / df['total_order_count']\n    df['liquidity_weight'] = (df['bid_volume_1'] + df['ask_volume_1']) / (df['bid_volume_2'] + df['ask_volume_2'] + 1e-9)\n\n    # Market pressure features\n    df['market_pressure'] = (df['recent_buy_order_count'] - df['recent_sell_order_count']) / df['total_order_count']\n    df['order_book_pressure'] = df[[f'bid_volume_{i}' for i in range(1, 6)]].sum(axis=1) / (df[[f'ask_volume_{i}' for i in range(1, 6)]].sum(axis=1) + 1e-6)\n\n    # Price sensitivity features\n    df['bid_price_sensitivity'] = (df['bid_price_5'] - df['bid_price_1']) / df[['bid_volume_1', 'bid_volume_5']].sum(axis=1)\n    df['ask_price_sensitivity'] = (df['ask_price_5'] - df['ask_price_1']) / df[['ask_volume_1', 'ask_volume_5']].sum(axis=1)\n\n    # Volume-weighted average price (VWAP) features\n    for i in range(1, 6):\n        df[f'vwap_{i}'] = (df[f'bid_price_{i}'] * df[f'bid_volume_{i}'] + df[f'ask_price_{i}'] * df[f'ask_volume_{i}']) / (df[f'bid_volume_{i}'] + df[f'ask_volume_{i}'] + 1e-9)\n\n    # Relative volume features\n    df['rvbb'] = df['bid_volume_1'] / df[[f'bid_volume_{i}' for i in range(1, 6)]].sum(axis=1)\n    df['rvba'] = df['ask_volume_1'] / df[[f'ask_volume_{i}' for i in range(1, 6)]].sum(axis=1)\n    df['rvbf'] = df['rvba'] + df['rvbb']\n\n    # Price difference features\n    for i in range(1, 5):\n        df[f'bid_price_diff_{i}_{i+1}'] = df[f'bid_price_{i}'] - df[f'bid_price_{i+1}']\n        df[f'ask_price_diff_{i}_{i+1}'] = df[f'ask_price_{i+1}'] - df[f'ask_price_{i}']\n\n    # Mean price and volume features\n    df['ask_price_mean'] = df[[f'ask_price_{i}' for i in range(1, 6)]].mean(axis=1)\n    df['bid_price_mean'] = df[[f'bid_price_{i}' for i in range(1, 6)]].mean(axis=1)\n    df['ask_volume_mean'] = df[[f'ask_volume_{i}' for i in range(1, 6)]].mean(axis=1)\n    df['bid_volume_mean'] = df[[f'bid_volume_{i}' for i in range(1, 6)]].mean(axis=1)\n\n    # Cumulative sum features\n    df['ask_price_cumsum'] = df[[f'ask_price_{i}' for i in range(1, 6)]].cumsum(axis=1).iloc[:, -1]\n    df['bid_price_cumsum'] = df[[f'bid_price_{i}' for i in range(1, 6)]].cumsum(axis=1).iloc[:, -1]\n    df['ask_vol_cumsum'] = df[[f'ask_volume_{i}' for i in range(1, 6)]].cumsum(axis=1).iloc[:, -1]\n    df['bid_vol_cumsum'] = df[[f'bid_volume_{i}' for i in range(1, 6)]].cumsum(axis=1).iloc[:, -1]\n    df['accumulated_price_diff'] = df['ask_price_cumsum'] - df['bid_price_cumsum']\n    df['accumulated_volume_diff'] = df['ask_vol_cumsum'] - df['bid_vol_cumsum']\n\n    # Volume momentum features\n    df['bid_volume_momentum'] = df[[f'bid_volume_{i}' for i in range(1, 6)]].diff(axis=1).sum(axis=1)\n    df['ask_volume_momentum'] = df[[f'ask_volume_{i}' for i in range(1, 6)]].diff(axis=1).sum(axis=1)\n\n    # Market skew feature\n    df['market_skew'] = ((df['bid_volume_1'] - df['ask_volume_1']) + (df['bid_volume_2'] - df['ask_volume_2'])) / ((df['bid_volume_1'] + df['ask_volume_1']) + (df['bid_volume_2'] + df['ask_volume_2']) + 1e-9)\n\n    # Depth imbalance features\n    df['depth_imbalance'] = (df['bid_volume_1'] + df['bid_volume_2']) / (df['ask_volume_1'] + df['ask_volume_2'] + 1e-9)\n    # First, create individual depth imbalance features\n    for level in range(1, 6):\n        df[f'depth_imbalance_{level}'] = df[f'bid_volume_{level}'] / (df[f'ask_volume_{level}'] + 1e-9)\n\n    # Then, create the cumulative depth imbalance\n    df['cumulative_depth_imbalance'] = df[[f'depth_imbalance_{level}' for level in range(1, 6)]].sum(axis=1)\n\n    # Create depth imbalance full\n    df['depth_imbalance_full'] = df[[f'bid_volume_{i}' for i in range(1, 6)]].sum(axis=1) / df[[f'ask_volume_{i}' for i in range(1, 6)]].sum(axis=1)\n    # Additional ratio features\n    df['depth_ratio_bid'] = df['bid_volume_1'] / df[[f'bid_volume_{i}' for i in range(1, 6)]].sum(axis=1)\n    df['depth_ratio_ask'] = df['ask_volume_1'] / df[[f'ask_volume_{i}' for i in range(1, 6)]].sum(axis=1)\n    df['volume_concentration_1'] = df['bid_volume_1'] / (df['bid_volume_1'] + df['bid_volume_2'] + 1e-9)\n    \n    #Volatility Estimator (Microprice)\n    df['microprice'] = (df['bid_price_1'] * df['ask_volume_1'] + df['ask_price_1'] * df['bid_volume_1']) / \\\n                       (df['bid_volume_1'] + df['ask_volume_1'])\n    #Weighted Price Depth\n    df['weighted_price_depth'] =  ((df[[f'bid_price_{i}' for i in range(1, 6)]] * df[[f'bid_volume_{i}' for i in range(1, 6)]]).sum(axis=1) + (df[[f'ask_price_{i}' for i in range(1, 6)]] * df[[f'ask_volume_{i}' for i in range(1, 6)]]).sum(axis=1))  / ((df[[f'bid_volume_{i}' for i in range(1, 6)]]).sum(axis=1) + (df[[f'ask_volume_{i}' for i in range(1, 6)]]).sum(axis=1))\n\n    #Order Imbalance\n    df['order_imbalance'] = (df[['bid_volume_1', 'bid_volume_2', 'bid_volume_3', 'bid_volume_4', 'bid_volume_5']].sum(axis=1) - \n                             df[['ask_volume_1', 'ask_volume_2', 'ask_volume_3', 'ask_volume_4', 'ask_volume_5']].sum(axis=1)) / \\\n                            (df[['bid_volume_1', 'bid_volume_2', 'bid_volume_3', 'bid_volume_4', 'bid_volume_5']].sum(axis=1) + \n                             df[['ask_volume_1', 'ask_volume_2', 'ask_volume_3', 'ask_volume_4', 'ask_volume_5']].sum(axis=1))\n\n    return df\n\n# Apply features on both train and test data\ntrain_data = create_features(train_data)\ntest_data = create_features(test_data)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T18:22:18.104329Z","iopub.execute_input":"2024-09-16T18:22:18.104742Z","iopub.status.idle":"2024-09-16T18:22:21.081481Z","shell.execute_reply.started":"2024-09-16T18:22:18.104702Z","shell.execute_reply":"2024-09-16T18:22:21.080343Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#The features to be applied\nfeatures = [\n    'accumulated_price_diff', 'accumulated_volume_diff', 'ask_price_1', 'ask_price_2', 'ask_price_3', 'ask_price_4',\n    'ask_price_5', 'ask_price_diff_1_2', 'ask_price_diff_2_3', 'ask_price_diff_3_4', 'ask_price_diff_4_5',\n    'ask_price_mean', 'ask_volume_1', 'ask_volume_2', 'ask_volume_3', 'ask_volume_4', 'ask_volume_5',\n    'ask_volume_mean', 'ask_volume_momentum', 'ask_vol_cumsum', 'bid_ask_imbalance', 'bid_ask_slope',\n    'bid_price_1', 'bid_price_2', 'bid_price_3', 'bid_price_4', 'bid_price_5', 'bid_price_diff_1_2',\n    'bid_price_diff_2_3', 'bid_price_diff_3_4', 'bid_price_diff_4_5', 'bid_price_mean', 'bid_price_sensitivity',\n    'bid_volume_1', 'bid_volume_2', 'bid_volume_3', 'bid_volume_4', 'bid_volume_5', 'bid_volume_mean',\n    'bid_volume_momentum', 'bid_vol_cumsum', 'depth', 'depth_imbalance', 'depth_imbalance_1', 'depth_imbalance_2',\n    'depth_imbalance_3', 'depth_imbalance_4', 'depth_imbalance_5', 'last_trade_price', 'liquidity_impact',\n    'liquidity_weight', 'market_depth_ratio', 'market_pressure', 'market_skew', 'midprice_1', 'midprice_2',\n    'midprice_3', 'midprice_4', 'midprice_5', 'midprice_slope', 'microprice', 'order_flow_imbalance',\n    'order_imbalance', 'price_momentum', 'recent_buy_order_count', 'recent_sell_order_count', 'rvba', 'rvbb', 'rvbf',\n    'spread_depth_ratio_1', 'spread_skew', 'volume_concentration_1', 'volume_imbalance_1', 'volume_imbalance_2',\n    'volume_imbalance_3', 'volume_imbalance_4', 'volume_imbalance_5', 'vwap_1', 'vwap_2', 'vwap_3', 'vwap_4',\n    'vwap_5', 'weighted_mid_price_1', 'weighted_price_depth', 'weighted_spread_1', 'weighted_spread_2',\n    'weighted_spread_3', 'weighted_spread_4', 'weighted_spread_5'\n]","metadata":{"execution":{"iopub.status.busy":"2024-09-16T18:22:21.083692Z","iopub.execute_input":"2024-09-16T18:22:21.084325Z","iopub.status.idle":"2024-09-16T18:22:21.092790Z","shell.execute_reply.started":"2024-09-16T18:22:21.084274Z","shell.execute_reply":"2024-09-16T18:22:21.091547Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Note on Deprecation Warnings\n\nYou may see the following deprecation warnings when running the code:\n\n/tmp/ipykernel_56674/3187598405.py:6: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  X = X.fillna(method='ffill').fillna(method='bfill')\n/tmp/ipykernel_56674/3187598405.py:7: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  y = y.fillna(method='ffill').fillna(method='bfill')\n\n\nThese errors are just deprecation ones and do not affect the functionality of our code, and hence can be ignored for working purposes.","metadata":{}},{"cell_type":"code","source":"# Prepare the data\nX = train_data[features]\ny = train_data['actual_returns']\n\n# Fill NaN values\nX = X.fillna(method='ffill').fillna(method='bfill')\ny = y.fillna(method='ffill').fillna(method='bfill')\n\n# Scale features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Split the data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n\n# Create and train a Ridge regression model with cross-validation\nparam_grid = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\nridge = Ridge(random_state=42)\ngrid_search = GridSearchCV(ridge, param_grid, cv=5, scoring='neg_mean_squared_error')\ngrid_search.fit(X_train, y_train)\n\n# Get the best model\nbest_model = grid_search.best_estimator_\n\n# Predict on validation set\ny_val_pred = best_model.predict(X_val)\n\n# Calculate correlation\ncorrelation = np.corrcoef(y_val, y_val_pred)[0, 1]\nprint(f\"Validation Correlation: {correlation}\")\nprint(f\"Best alpha: {grid_search.best_params_['alpha']}\")\n\n# Predict on test data\ntest_features = test_data[features].fillna(method='ffill').fillna(method='bfill')\ntest_features_scaled = scaler.transform(test_features)\ntest_predictions = best_model.predict(test_features_scaled)","metadata":{"execution":{"iopub.status.busy":"2024-09-16T18:22:22.348510Z","iopub.execute_input":"2024-09-16T18:22:22.348963Z","iopub.status.idle":"2024-09-16T18:22:34.602909Z","shell.execute_reply.started":"2024-09-16T18:22:22.348918Z","shell.execute_reply":"2024-09-16T18:22:34.601331Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_36/3187598405.py:6: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  X = X.fillna(method='ffill').fillna(method='bfill')\n/tmp/ipykernel_36/3187598405.py:7: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  y = y.fillna(method='ffill').fillna(method='bfill')\n","output_type":"stream"},{"name":"stdout","text":"Validation Correlation: 0.42694585508662025\nBest alpha: 0.01\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/3187598405.py:34: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n  test_features = test_data[features].fillna(method='ffill').fillna(method='bfill')\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Create submission file\nsubmission = pd.DataFrame({\n    'timestamp_code': test_data['timestamp_code'],\n    'predicted_returns': test_predictions\n})\n\n# Ensure we have exactly 104980 rows\nassert len(submission) == 104980, f\"Submission has {len(submission)} rows instead of 104980\"\n\nsubmission.to_csv('submission.csv', index=False)\nprint(f\"Submission file created with {len(submission)} rows\")","metadata":{"execution":{"iopub.status.busy":"2024-09-16T18:22:34.605176Z","iopub.execute_input":"2024-09-16T18:22:34.605617Z","iopub.status.idle":"2024-09-16T18:22:34.916201Z","shell.execute_reply.started":"2024-09-16T18:22:34.605571Z","shell.execute_reply":"2024-09-16T18:22:34.915152Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Submission file created with 104980 rows\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}